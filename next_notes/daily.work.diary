***  update this everyday, in this table, dont open new table. So that I can find sth easily  ***


20120618
jobs: 
1: sas weekly release; 
2: add phrase_id for Johnny's seo_expr13 data set, the work is done in folder seo13, need to modify these codes to be uniformly used by other exprs;  
3: for the top_visits in the query table, need to find way to re-sort by high volume visits and low conversation, since conv is continuous, we need to test how to sort in this way.
4: for seo revenue model, how to create the deployment score data? (get phrase with attrs from phrase table, and then get features like rpv from rpt_pub_rpv_custom_store table)
5: make clear the difference of visitnew, rep_click2, rpt_pub_rpv_phrase, campaign_cost_report, campaign_revenue_report.

program is in:  sas4:/usr/home/hsong/work/test/compare.visitnew.repclick2.sas

visitnew: each record is for one visit, click_count is the clicks. for one visit, clicks may > 1 since people may click different products. It has keyword, pub_keywords, discard, ad_node_id, publisher_id. From ad_node_id we can get category name. from publisher_id we can restrict to seo or sem only and restrict to a given market. (in different market, phrase_id will be different, publisher_id will be different).

rep_click2: data is at kw/ptitle level. it also has ad_node_id and publisher_id. it has ptitle_id so we know which product did people click. CMP_KEYWORD is the keyword. it has cpc sot we can get our revenue(in fact, here cpc is our revenue). it also has price, search_keyword, discard.

rpt_pub_rpv_phrase: it has id(phrase_id), market_id, publisher_id, visits, clicks, revenue, cost, impressions, report_date, spider_visits, and report_date



20120619
jobs:
1: work on top_vis_query.sas to re-rank the data. We are trying visits/(conv+.02) to check the result. Dis with Cindy.
2: For seo_kws_revenue model. check more details about output from EMiner. More details about decision tree. If attrs are missing, we first impute them. Then for the nominal attr variables, we transform them by group rare levels. Fot interval variables, it will not transform automatically. But we manualls do log transform for some variables. 
3: check the git checked in code for Shirley
4: download data from visitnew table and prepare experiments for Lawrence
5: test the seo.visitnew.v6.exp.sas, allow gg only, no gg, and all pub_groups. It has been virified that all=gg yes+gg no. So next time it is easy to use this program directly.


SAS DECISION TREE Stduy Notes:

1:	Basic Concepts

maximum branch:		maximum number of branches that you want a decision tree to generate. 2-100
maximum depth:		maximun number of generations of nodes that you want to allow in your decision tree. 1-50
minimum categorical size:	specify the minimum number of training obs that a categorical value must have before the category can be used in a split search.
leaf size:	specify the minimum number of training obs that are allowed in a leaf.

2:	Prune and Subtree Selection
	1: a node will not split if:	
		1: the node contains few obs, as specified in the Node Sample Property option
		2: it has reached the Maximum Depth Property
		3: no split exceeds the threshold specified in the F test or Chi-Square significance level value

3:	sas help doc also list comparison of Decision Tree with CHAID, and how to approx CHAID in SAS using DT


SAS PROC SQL  JOIN / UNION / EXCEPT  study notes
UNION: http://support.sas.com/documentation/cdl/en/sqlproc/62086/HTML/default/viewer.htm#a001361224.htm
PROC SQL: http://www.okstate.edu/sas/v8/sashtml/proc/zljoined.htm



20120620
jobs
1: sas ops as required by group members, kill scr jobs and the inside sas programs
2: check error report in sas
3: prepare data for SEO experiments
4: check the deletion model and deployment model--use buckets cover performance to compare different model
5: meeting with seo team, how to make the experiment more reliable, how to get confidence about this: 
	one way I think is use may1 to may14 as sample, then use each days data from may15-jun15 to calculate CI, or p-value or something like this.
	one Johnny give: use sth called beta value to calcuate each kw on each day for one year period, then we can pick kws with stable and low beta value to do
	one shenglei give: use more data



20120621
jobs
1: check with Prathibha and zixin on how to assign revenue from keyword to each leafnode or to the adnode
2: Cindy's question on how to pick the threshold for visits and conv?i
3: think about the confidence: use may1 to may14 to sample, use next 4 weeks data (may15 to jun11) to calculate the pct of visits, revenue, clicks for fake test over control(this 4 weeks data has no experiments on it). Then we can calculate the confidence from these 28 data points. 
4: prepare the deployment data for seo revenue model
5: sample kws for expr13, thinking of how to measure the data in experiments

Proc transpose study
http://www.ats.ucla.edu/stat/sas/modules/ltow_transpose.htm



20120622
jobs
1: prepare sas program for seo kws experiments from sas jsp
2: prepare seo expr kws result check program for sas jsp
3: group meeting, learn about how to access hadoop from SAS
4: Talk with Young about how to make our results usable for them, should use srank_keyword_sr2 table

SAS generate java but score part maybe problems or slow. One way is to use java libraries directly.

Hadoop & Cassandra 
H: traffice catelog
C: which team use? how good it is?


20120623
jobs
1: study again about git: remote repo, git push origin local:remote
2: finish the program of SEO sample, learn how to use %do %until for several conditions
3: learn about hadoop


20120624
jobs
1: watch hadoop video
2: finish visitnew download table, keep 60 day data, aggregate data in kw/report_date/category_id level, is it fine?
3: finish the SEO expr track program and prepare for jsp


20120625
jobs
1: results for L(check the result with before to make sure consistent), and prepare data for visitnew.data.incr.sas and check the historical data because it shows 23jun data is finished this morning. (1 hr)
2: check for J's expr result: add category_id, then analyze by different category:wq
3: check in the code to sas3, set up jsp for track part job and sas recurring task for download job
4: one hr meeting for search solr vs the old one.
5: sample new kws and check them in group/category level to make sure they are close.



20120626
jobs
1: sas 736 weekly deploy and send out for verify
2: CJ's code change in sas server. sas ops
3: double check the seo program in sas3, since yesterday copy was removed by sas weekly release. Several things to take care: 1)the downloaded visitnew table should be pay attention, in the code replace all "temp_hsong" by "temp_sasprod"  2)a good way is when deploy codes, set data path the same as sasprod did.
4: check J's experiment result at each catid. first add category_id into the sample data, then just in seo.visitnew.v6.exp.sas, in "data to_report" part add "where category_id=3". That's it! Then do it for each category. (the check job is done in sas3 seo8b)
5: Prepare for the seo_kws_revenue model meeting: check with Y more detailed about how currently he use the kws(aggregate data from rep_click2 at kw/node level, then pick whose clicks>=2 in last 2 months). 
Things to do: 1)check the true_target_revenue, true_sem_revenue and proj_target_revenue, find a scale to balance sem_revenue and proj_target_revenue 2)sas prod read access to table srank_keyword_sr

If SAS code is copied to sasprod before really checked in, it's better to make a copy in my own folder. otherwise after weekly release, all codes and the dir will be removed.



20120627
jobs
1: check for J if the high visits kws (like visits>10) differs from the low ones(1 hr). It shows the result is similar to the total. Fow visits<=10 kws, their drop is smaller than the high volume kws. but these low volume kws has only a small proportion of visits, revenue and clicks. Sample new kws for seo team for experiment 12(12b).
2: download attrs and check the result, forward err msg, kick off job for xd in sas5, file cc to read srank table
3: test seo model without transformation, give the summary result(in sas5, deploy.bucket.compare.sas delete.bucket.compare.sas and check.sas to give sum of p_target_rev). 
4: Try to pick a good value for the seo sample code, top button like 95%, 97% or 99% quantile? (did in sas3, seo.kws.expr.samp.sasjsp.sas). Conclusion is: For deploy model, use attrs and sem_prior_rev in the model without log transformation. For deletion model, if cares about 0 bucket coverage, then use log transform; if cares about error terms, use no log transform.

SAS: how to calculate percentiles not automatically?
http://www.ats.ucla.edu/stat/sas/faq/percentiles.htm



20120628
jobs
1: improve the seo.kws.expr.samp.sasjsp.sas code. Previously I use the condition (median visits<=visits<=95% percentile visits)  and  (median revenue <=visits<=95% percentile revenue) to pick the sample pool. This pool its revenue is about 29.66% revenue of all. Then we can 95% to 99% percentiles separately to test, it shows 98% percentile will cover about 44% of rev, 99% percentile will cover about 53% of rev (the detailed is in sas3(/work/seo/seo>seo.kws.expr.samp.sasjsp.sas). So at last we will pick 98% percentile. (2 hrs).More details is in today's email sent out.
2: improve the codes for seo.visitnew.v6.expr.sas. Use S to simply the codes by using proc summary rather than using data steps to do it.
3: Improve the seo revenue model

Check: proc summary, class , var ,  mean=,  what is that mean really for:  



20120629
jobs
1: seo revenue model, clicks and revenue are highly correlated, need to remove one in the model to avoid multi-collinarity. In this way, we will re-evaluate the model
2: check the top_vis_query to find a solution
3: 



20120630
jobs



20120701
jobs



20120702
jobs
1: check the errors for seo_revenue model: in the validate output, log_target_revenue is the transform of target revenue, P_log_target_revenue is the prediction of log_target_revenue, R_log_target_revenue is the error of log_target_revenue and P_log_target_revenue. V_log_target_revenue is the same as log_target_revenue.
2: meeting with SL, should finalize the seo_revenue jobs this week. In the future there may be other works from WZC.
3: check SEO exp results for J. by category it shows for some categories the visits increase. By theorey, Cat "others" sbould be less than 10% in all. But when aggregate into kws level, it increased to about 21% by counts. and it is over 40% for visits revenue clicks. Why? one reason I think is one phrase was mapped to several category_id and proc summary only picks the largest one. Any other reason? If have time, it's good to drill on this question.



20120703
jobs
1: schedule sas jobs for SB, kick off jobs for Sam
2: an error in sas weekly releae: when ftp from my desktop to server using ftp type as TEXT, this causes the error. should use DEFAULT. But when ftp csv file from windows to unix, use text otherwise there will be symbol like ^M.
3: Meeting with J and SL for seo revenue model. asjust the p_log_target_revenue by mean(exp(r_log_target_revenue)) or using the ratio of sum(target_revenue)/sum(p_target_revenue) from training data to adjust data
4: combine the code prep.seo.score.deployment.sas and prep.seo.score.deletion.sas into prep.seo.score.data.sas in SAS3 and finalize this code. 


20120704
jobs
Holiday. Learn R: aggregate, merge  v.s. SAS: proc summary, merge



20120705
jobs
1: check the result of seo revenue model. If the adjusted coefficient use mean(exp(r_log_target_revenue)) then the adjusted predicted target revenue will be very large since mean(exp(r_log_target_revenue)) is over 200.
So, maybe it is better to use ratio = sum(target_revenue)/sum(exp(p_log_target_revenue)) as the adjusted coefficient. 
log_transform: deletion model with log_other_revenue_prior or  without it, check the sign of coefficient
no_transform: deletion model with other_revenue_prior or without it, check the sign of coefficient



20120706
jobs
1: finalize the SEO revenue model, wait for deploy of this model
2: start the work on Fansnap model: learn about the data, what does they mean, how the proj_rate and proj_rev are calculated



20120707
jobs
1: meet with Dr Lii about the slides


20120708
jobs
1: prepate slides for Dr. Lii; learn a little about R



20120709
jobs
1: check the data for fansnap: how the excel do, what we want to do, more details about the data and tables
2: proc datasets,  proc catalog details



20120710
jobs
1: in cpa_items, for jan2012, final_commission is missing for all, calculated_commission=commission_percent*gross_sales. so, how to get commission for the excel file?
2: for data clk_1201, order_size cost over payer_id category_id is similar to the result in the excel file.
3: it's also checked revenue from revenue details tables is different from the commission in the excel file
4: when merge cpa_items with click_1201, there are some obs only in cpa_items not in click_1201, which means those obs have no clicks but got cpa. Does this mean they are from the previous month clicks? or why?
5: recovery data in table TN-Jan-Cat, still Sarvesh did not explain clearly how to get commission and Cat in the excel file.

vim: how to replace a line? e.g., I need to replace all "," in the following line into blanks:
: payer_id, fsid, payer_name, category_id, ticket_revenue_percentage, revenue_percentage, revenue, gross_sales, ticket_qty, order_qty
in vim, it is done by:  :.s/,/ /g


20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs




20120708
jobs




20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs



20120708
jobs





